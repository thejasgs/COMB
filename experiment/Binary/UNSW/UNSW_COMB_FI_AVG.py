# -*- coding: utf-8 -*-
"""Talking_None.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1DLqJwCeAOyqh61a3WfXPMwIXSem1U_W3

# Importing the Data
"""

import sys
print("File: ",sys.argv[0])

import numpy as np # linear algebra
import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)
from sklearn.metrics import classification_report, accuracy_score

# from google.colab import drive

# drive.mount('/content/gdrive')
# root_path = 'gdrive/My Drive/Research/Benchmarks/'  #change dir to your project folder

# data_set = 'Talking_Data'  #@param {type: "string"}
root_path = '../../datasets/'
#cleaned data without non-attack values
# X = pd.read_csv(root_path+data_set+'.csv', index_col=0, usecols=[i for i in range(12)])
# Y = pd.read_csv(root_path+data_set+'.csv', usecols=[12])

data_set = 'UNSW-NB15'  #@param {type: "string"}
df = pd.read_csv(root_path+data_set+'.csv', header=None)
df.shape

#Data Cleaning
df.columns=['srcip','sport','dstip','dsport',
'proto',
'state',
'dur',
'sbytes',
'dbytes',
'sttl',
'dttl',
'sloss',
'dloss',
'service',
'Sload',
'Dload',
'Spkts',
'Dpkts',
'swin',
'dwin',
'stcpb',
'dtcpb',
'smeansz',
'dmeansz',
'trans_depth',
'res_bdy_len',
'Sjit',
'Djit',
'Stime',
'Ltime',
'Sintpkt',
'Dintpkt',
'cprtt',
'synack',
'ackdat',
'is_sm_ips_ports',
'ct_state_ttl',
'ct_flw_http_mthd',
'is_ftp_login',
'ct_ftp_cmd',
'ct_srv_src',
'ct_srv_dst',
'ct_dst_ltm',
'ct_src_ ltm',
'ct_src_dport_ltm',
'ct_dst_sport_ltm',
'ct_dst_src_ltm',
'attack_cat',
'Label']

df=df.drop(df.columns[:4],axis=1)

df = df.drop(columns=['attack_cat'])

df = df.dropna()

#

df['ct_ftp_cmd']=df['ct_ftp_cmd'].replace([0, 1, 6, 2, 4, 8, 5, 3, '0', '1', ' ', '2', '4'],[0,1,6,2,4,8,5,3,0,1,0,2,4])

#

l1=list(np.arange(len(df['state'].unique())))
df['state']=df['state'].replace(['CON', 'INT', 'FIN', 'URH', 'REQ', 'ECO', 'RST', 'CLO', 'TXD',
       'URN', 'no', 'ACC', 'PAR', 'MAS', 'TST', 'ECR'],l1)

l1=list(np.arange(len(df['service'].unique())))
df['service']=df['service'].replace(['-', 'http', 'smtp', 'pop3', 'snmp', 'ftp', 'ftp-data', 'ssl',
       'irc', 'dns', 'radius', 'dhcp', 'ssh'],l1)

l1=list(np.arange(len(df['proto'].unique())))
df['proto']=df['proto'].replace(['udp', 'arp', 'tcp', 'ospf', 'icmp', 'igmp', 'sctp', 'udt', 'sep',
       'sun-nd', 'swipe', 'mobile', 'pim', 'rtp', 'ipnip', 'ip', 'ggp',
       'st2', 'egp', 'cbt', 'emcon', 'nvp', 'igp', 'xnet', 'argus',
       'bbn-rcc', 'chaos', 'pup', 'hmp', 'mux', 'dcn', 'prm', 'trunk-1',
       'xns-idp', 'trunk-2', 'leaf-1', 'leaf-2', 'irtp', 'rdp', 'iso-tp4',
       'netblt', 'mfe-nsp', 'merit-inp', '3pc', 'xtp', 'idpr', 'tp++',
       'ddp', 'idpr-cmtp', 'ipv6', 'il', 'idrp', 'ipv6-frag', 'sdrp',
       'ipv6-route', 'gre', 'rsvp', 'mhrp', 'bna', 'esp', 'i-nlsp',
       'narp', 'ipv6-no', 'tlsp', 'skip', 'ipv6-opts', 'any', 'cftp',
       'sat-expak', 'kryptolan', 'rvd', 'ippc', 'sat-mon', 'ipcv', 'visa',
       'cpnx', 'cphb', 'wsn', 'pvp', 'br-sat-mon', 'wb-mon', 'wb-expak',
       'iso-ip', 'secure-vmtp', 'vmtp', 'vines', 'ttp', 'nsfnet-igp',
       'dgp', 'tcf', 'eigrp', 'sprite-rpc', 'larp', 'mtp', 'ax.25',
       'ipip', 'micp', 'aes-sp3-d', 'encap', 'etherip', 'pri-enc', 'gmtp',
       'pnni', 'ifmp', 'aris', 'qnx', 'a/n', 'scps', 'snp', 'ipcomp',
       'compaq-peer', 'ipx-n-ip', 'vrrp', 'zero', 'pgm', 'iatp', 'ddx',
       'l2tp', 'srp', 'stp', 'smp', 'uti', 'sm', 'ptp', 'fire', 'crtp',
       'isis', 'crudp', 'sccopmce', 'sps', 'pipe', 'iplt', 'unas', 'fc',
       'ib'],l1)

X=df.iloc[:,:-1]
Y=df.iloc[:,-1:]

from sklearn.preprocessing import StandardScaler
X=X.astype('float')
scaler = StandardScaler()
X = scaler.fit_transform(X)
X = pd.DataFrame(X)
# Data Balancing
from imblearn.over_sampling import SMOTE
sm = SMOTE(random_state=0)
X, Y = sm.fit_resample(X, Y.values.ravel())
X, Y = pd.DataFrame(X), pd.DataFrame(Y)

"""# Feature Engineering"""

 # imports
from sklearn.ensemble import RandomForestClassifier as rf
from sklearn.metrics import accuracy_score
from sklearn.cluster import MiniBatchKMeans
from sklearn.metrics import homogeneity_completeness_v_measure as hcv

score = []
for i in range(len(X.columns)): # loop number of features
    K = MiniBatchKMeans(n_clusters=len(Y[Y.columns[0]].unique()), random_state=0)
    pred = K.fit_predict(X.iloc[:, [i]].values)
    h,c,v = hcv(Y[Y.columns[0]].values,pred)
    score.append(np.mean([h,c,v]))



# Rank the features and sort

s2 = score
np.asarray(s2)

s1 = []
for i in range(len(X.columns)):
    s1.append(i)

np.asarray(s1)

li = list(zip(s1, s2))

def sortSecond(val): 
    return val[1] 

li.sort(key = sortSecond, reverse=True) 

# Create a copy of X dataframe with columns sorted by score

titles = []

for i in range(len(X.columns)):
    p = X.columns[li[i][0]]
    titles.append(p)


X1 = pd.DataFrame(columns=titles)

for i in range(len(X.columns)):
    X1[X1.columns[i]] = X[X.columns[li[i][0]]]


# Recursive Feature Elemination from # of features to 0 and keep the accuracy score of each
max_accuracy = 0
accuracy = []
X2 = X1.copy()
X1 = pd.DataFrame()
# for i in range(len(X1.columns)-1,-1,-1):
for i in range(0,len(X2.columns)): 
    # add a feature
    X1 = pd.concat([X1, X2[X2.columns[i]]], axis=1)
#     X1.join(X2[X2.columns[i]])
    # begin cross-validation
    cv_accuracy =[]
    from sklearn.model_selection import StratifiedKFold
    kf = StratifiedKFold(n_splits=5, random_state=0)
    for train, test in kf.split(X1,Y):
        # classifyer
        r = rf(random_state=0, n_jobs=-1, n_estimators=10) 
        # train test split
        x_train = X1.iloc[train]
        x_test = X1.iloc[test]
        y_train = Y.iloc[train]
        y_test = Y.iloc[test]
        r.fit(x_train, y_train.values.ravel())
        y_pred = r.predict(x_test)
        cv_accuracy.append(accuracy_score(y_test, y_pred)) 
    accuracy.append(np.mean(cv_accuracy))

    if np.mean(cv_accuracy)>=max_accuracy:
      max_accuracy = np.mean(cv_accuracy)
    elif np.mean(cv_accuracy)<max_accuracy:
      X1 = X1.iloc[:, :-1]
    
# best score calcuation
# index = accuracy.index(max(accuracy))
# X = X2.iloc[:,0:len(X.columns)-index]
X = X1.copy()

"""# Performance Analysis"""

# must have X and Y
from sklearn.model_selection import StratifiedKFold
from sklearn.ensemble import RandomForestClassifier as rf

from sklearn.preprocessing import LabelBinarizer
from sklearn.metrics import roc_auc_score, f1_score, precision_score, recall_score, accuracy_score

# handle multiclass classification
def multiclass_roc_auc_score(y_test, y_pred, average="weighted"):
  lb = LabelBinarizer()
  lb.fit(y_test)
  y_test = lb.transform(y_test)
  y_pred = lb.transform(y_pred)
  return roc_auc_score(y_test, y_pred, average=average)

# define metrics
accuracy = []
precision = []
recall =[]
f1=[]
roc_auc=[]

# begin cross-validation
kf = StratifiedKFold(n_splits=5, random_state=0)
for train, test in kf.split(X,Y):
  # classifyer
  r = rf(random_state=0, n_jobs=-1, n_estimators=10) 
  # train test split
  X1 = X.iloc[train]
  X2 = X.iloc[test]
  Y1 = Y.iloc[train]
  Y2 = Y.iloc[test]
  # fit
  r.fit(X1,Y1.values.ravel())
  # predict
  Y_pred = r.predict(X2)
  Y_pred = pd.DataFrame(Y_pred)

  # metrics
  accuracy.append(accuracy_score(Y2, Y_pred))
  f1.append(f1_score(Y2, Y_pred, average="weighted"))
  precision.append(precision_score(Y2, Y_pred, average="weighted"))
  recall.append(recall_score(Y2, Y_pred, average="weighted"))
  roc_auc.append(multiclass_roc_auc_score(Y2, Y_pred, average="weighted"))

# print averages
print("Average Accuracy: ",np.mean(accuracy))
print("Average Precision: ",np.mean(precision))
print("Average Recall: ",np.mean(recall))
print("Average F1: ",np.mean(f1))
print("Average ROC_AUC: ", np.mean(roc_auc))
print("Features Selected ", X.shape[1])