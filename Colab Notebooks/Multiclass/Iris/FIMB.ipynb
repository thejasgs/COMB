{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Iris_ RF w/FS (Minibatch+fowlkes).ipynb","version":"0.3.2","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"6tlOZLHCTreA","colab_type":"text"},"source":["# Importing the Data"]},{"cell_type":"markdown","metadata":{"id":"sH7d0Oa5uV2o","colab_type":"text"},"source":["**Goal**: Classify attacks assuming a multiclass classification system has alerted an attack."]},{"cell_type":"code","metadata":{"id":"H3iMA4-iLjxI","colab_type":"code","colab":{}},"source":["import matplotlib.pyplot as plt\n","%matplotlib inline \n","\n","import numpy as np # linear algebra\n","import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n","import seaborn as sns \n","\n","from sklearn.metrics import classification_report, accuracy_score"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"NuVI_cCqIYUJ","colab_type":"code","outputId":"5ae8c302-d2e1-45a3-e828-7153bd63e34e","executionInfo":{"status":"ok","timestamp":1562353837663,"user_tz":240,"elapsed":469,"user":{"displayName":"Daniel Jimenez","photoUrl":"","userId":"03897706589372651705"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["from google.colab import drive\n","\n","drive.mount('/content/gdrive')\n","root_path = 'gdrive/My Drive/Research/Benchmarks/'  #change dir to your project folder"],"execution_count":11,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"rSRSysY6Kuln","colab_type":"code","colab":{}},"source":["#cleaned data without non-attack values\n","X = pd.read_csv(root_path+'Iris.csv', header=None, usecols=[i for i in range(4)])\n","Y = pd.read_csv(root_path+'Iris.csv', header=None, usecols=[4])"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IeoRB2PrkT4j","colab_type":"text"},"source":["# Feature Engineering"]},{"cell_type":"code","metadata":{"id":"3M052D-skWla","colab_type":"code","outputId":"80273c0d-490f-4cd4-b84a-6d3a1c3f5a12","executionInfo":{"status":"ok","timestamp":1562353839363,"user_tz":240,"elapsed":2127,"user":{"displayName":"Daniel Jimenez","photoUrl":"","userId":"03897706589372651705"}},"colab":{"base_uri":"https://localhost:8080/","height":199}},"source":["# cluster and score\n","from sklearn.cluster import MiniBatchKMeans\n","from sklearn.metrics.cluster import fowlkes_mallows_score as scorer\n","score = []\n","for i in range(len(X.columns)): # loop number of features\n","  K = MiniBatchKMeans(n_clusters=len(Y[Y.columns[0]].unique())-1, random_state=0)\n","  pred = K.fit_predict(X.iloc[:, [i]].values)\n","  s = scorer(Y[Y.columns[0]].values,pred)\n","  score.append(s)\n","  \n","\n","# Rank the features and sort\n","\n","s2 = score\n","np.asarray(s2)\n","\n","s1 = []\n","for i in range(len(X.columns)):\n","  s1.append(i)\n","  \n","np.asarray(s1)\n","\n","li = list(zip(s1, s2))\n","\n","def sortSecond(val): \n","    return val[1] \n","  \n","li.sort(key = sortSecond, reverse=True) \n","\n","\n","\n","    \n","# Create a copy of X dataframe with columns sorted by score\n","\n","titles = []\n","\n","for i in range(len(X.columns)):\n","  p = X.columns[li[i][0]]\n","  titles.append(p)\n","\n","\n","X1 = pd.DataFrame(columns=titles)\n","\n","for i in range(len(X.columns)):\n","  X1[X1.columns[i]] = X[X.columns[li[i][0]]]\n","  \n","  \n","\n","# imports\n","from sklearn.model_selection import train_test_split\n","from sklearn.ensemble import RandomForestClassifier as rf\n","from sklearn.metrics import accuracy_score\n","\n","# Recursive Feature Elemination from # of features to 0 and keep the accuracy score of each\n","\n","accuracy = []\n","X2 = X1.copy()\n","\n","# for i in range(len(X1.columns)-1,-1,-1):\n","for i in range(len(X1.columns)-1): \n","  x_train, x_test, y_train, y_test = train_test_split(X1, Y, test_size=0.2, random_state=11)\n","  X1.drop(X1.columns[len(X1.columns)-1], axis=1, inplace=True)\n","  clf = rf(random_state=0, n_jobs=-1)\n","  clf.fit(x_train, y_train)\n","  y_pred = clf.predict(x_test)\n","  accuracy.append(accuracy_score(y_test, y_pred)) \n","  \n","\n","  \n","# best score calcuation\n","index = accuracy.index(max(accuracy))\n","\n","X = X2.iloc[:,0:len(X.columns)-index]"],"execution_count":13,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n","  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n","/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n","  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n","/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n","  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"bf0nTitVLB6K","colab_type":"text"},"source":["# Performance Analysis"]},{"cell_type":"code","metadata":{"id":"AFREm3JwVGvv","colab_type":"code","colab":{}},"source":["from sklearn.model_selection import train_test_split\n","x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=11)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Tw_RpaU9K-mK","colab_type":"code","outputId":"b113ea07-60b4-4c8e-8038-914375d4c5ca","executionInfo":{"status":"ok","timestamp":1562353839737,"user_tz":240,"elapsed":2464,"user":{"displayName":"Daniel Jimenez","photoUrl":"","userId":"03897706589372651705"}},"colab":{"base_uri":"https://localhost:8080/","height":235}},"source":["from sklearn.ensemble import RandomForestClassifier as rf\n","clf = rf(random_state=0, n_jobs=-1)\n","clf.fit(x_train, y_train)"],"execution_count":15,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n","  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n","/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:3: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n","  This is separate from the ipykernel package so we can avoid doing imports until\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n","                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n","                       min_impurity_decrease=0.0, min_impurity_split=None,\n","                       min_samples_leaf=1, min_samples_split=2,\n","                       min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=-1,\n","                       oob_score=False, random_state=0, verbose=0,\n","                       warm_start=False)"]},"metadata":{"tags":[]},"execution_count":15}]},{"cell_type":"code","metadata":{"id":"JHXdA6izQNeA","colab_type":"code","outputId":"57724495-2b69-441c-aeea-6ba43251a5ef","executionInfo":{"status":"ok","timestamp":1562353839748,"user_tz":240,"elapsed":2461,"user":{"displayName":"Daniel Jimenez","photoUrl":"","userId":"03897706589372651705"}},"colab":{"base_uri":"https://localhost:8080/","height":107}},"source":["\n","x = list(zip(X.columns, clf.feature_importances_))\n","\n","def sortSecond(val): \n","    return val[1] \n","  \n","x.sort(key = sortSecond, reverse=True) \n","\n","for i in range(len(X.columns)):\n","    print(x[i])\n","    if (i==len(X.columns)-1):\n","      print(\"features\",i+1)"],"execution_count":16,"outputs":[{"output_type":"stream","text":["(3, 0.48188550903285493)\n","(2, 0.47390209487699864)\n","(0, 0.028536688468940384)\n","(1, 0.01567570762120602)\n","features 4\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"P-2HcTcES3zb","colab_type":"code","outputId":"329bbfb5-5b9c-4fb9-e2be-e253d72e5c3d","executionInfo":{"status":"ok","timestamp":1562353839910,"user_tz":240,"elapsed":2604,"user":{"displayName":"Daniel Jimenez","photoUrl":"","userId":"03897706589372651705"}},"colab":{"base_uri":"https://localhost:8080/","height":35}},"source":["print(clf.score(x_train, y_train), \"train\")"],"execution_count":17,"outputs":[{"output_type":"stream","text":["0.9916666666666667 train\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"7C0mP-QHrKrU","colab_type":"code","outputId":"f3df7ca7-c869-494c-c9bf-f89f9c983771","executionInfo":{"status":"ok","timestamp":1562353840034,"user_tz":240,"elapsed":2712,"user":{"displayName":"Daniel Jimenez","photoUrl":"","userId":"03897706589372651705"}},"colab":{"base_uri":"https://localhost:8080/","height":233}},"source":["y_pred = clf.predict(x_test)\n","\n","print(\"Classification\\n\")\n","print(classification_report(y_test,y_pred, digits=4))"],"execution_count":18,"outputs":[{"output_type":"stream","text":["Classification\n","\n","                 precision    recall  f1-score   support\n","\n","    Iris-setosa     1.0000    1.0000    1.0000         9\n","Iris-versicolor     0.8333    1.0000    0.9091        10\n"," Iris-virginica     1.0000    0.8182    0.9000        11\n","\n","       accuracy                         0.9333        30\n","      macro avg     0.9444    0.9394    0.9364        30\n","   weighted avg     0.9444    0.9333    0.9330        30\n","\n"],"name":"stdout"}]}]}